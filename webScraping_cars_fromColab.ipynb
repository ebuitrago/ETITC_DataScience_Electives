{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d95f2ef3"
      },
      "source": [
        "# Scraping Used Car Web Data: Case Study tucarrro.com (Colab version)\n",
        "[Author: Elias Buitrago Bolivar](https://github.com/ebuitrago?tab=repositories)\n",
        "\n",
        "This jupyter notebook depicts a python based web scraping  algorithm to obtain data to train a price car prediction machine learning algorithm. Used cars web data are extracted from [Tu Carro](www.tucarro.com.co). The code presented here is functional and was tested by scraping real data. This code version is compatible with Colab.\n",
        "_Updated: Feb 18, 2024_\n"
      ],
      "id": "d95f2ef3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc4c3640"
      },
      "source": [
        "## Install required libraries"
      ],
      "id": "bc4c3640"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79e2c30d",
        "outputId": "5ea67ba6-a30e-4b0e-badc-aa184a15702d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (4.9.4)\n",
            "Collecting scrapy\n",
            "  Downloading Scrapy-2.11.1-py2.py3-none-any.whl (287 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.8/287.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Twisted>=18.9.0 (from scrapy)\n",
            "  Downloading twisted-24.3.0-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from scrapy) (42.0.5)\n",
            "Collecting cssselect>=0.9.1 (from scrapy)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting itemloaders>=1.0.1 (from scrapy)\n",
            "  Downloading itemloaders-1.1.0-py3-none-any.whl (11 kB)\n",
            "Collecting parsel>=1.5.0 (from scrapy)\n",
            "  Downloading parsel-1.8.1-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: pyOpenSSL>=21.0.0 in /usr/local/lib/python3.10/dist-packages (from scrapy) (24.0.0)\n",
            "Collecting queuelib>=1.4.2 (from scrapy)\n",
            "  Downloading queuelib-1.6.2-py2.py3-none-any.whl (13 kB)\n",
            "Collecting service-identity>=18.1.0 (from scrapy)\n",
            "  Downloading service_identity-24.1.0-py3-none-any.whl (12 kB)\n",
            "Collecting w3lib>=1.17.0 (from scrapy)\n",
            "  Downloading w3lib-2.1.2-py3-none-any.whl (21 kB)\n",
            "Collecting zope.interface>=5.1.0 (from scrapy)\n",
            "  Downloading zope.interface-6.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.3/247.3 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protego>=0.1.15 (from scrapy)\n",
            "  Downloading Protego-0.3.0-py2.py3-none-any.whl (8.5 kB)\n",
            "Collecting itemadapter>=0.1.0 (from scrapy)\n",
            "  Downloading itemadapter-0.8.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from scrapy) (67.7.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from scrapy) (23.2)\n",
            "Collecting tldextract (from scrapy)\n",
            "  Downloading tldextract-5.1.1-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.7/97.7 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from scrapy) (4.9.4)\n",
            "Collecting PyDispatcher>=2.0.5 (from scrapy)\n",
            "  Downloading PyDispatcher-2.0.7-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->scrapy) (1.16.0)\n",
            "Collecting jmespath>=0.9.5 (from itemloaders>=1.0.1->scrapy)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from service-identity>=18.1.0->scrapy) (23.2.0)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.10/dist-packages (from service-identity>=18.1.0->scrapy) (0.5.1)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.10/dist-packages (from service-identity>=18.1.0->scrapy) (0.3.0)\n",
            "Collecting automat>=0.8.0 (from Twisted>=18.9.0->scrapy)\n",
            "  Downloading Automat-22.10.0-py2.py3-none-any.whl (26 kB)\n",
            "Collecting constantly>=15.1 (from Twisted>=18.9.0->scrapy)\n",
            "  Downloading constantly-23.10.4-py3-none-any.whl (13 kB)\n",
            "Collecting hyperlink>=17.1.1 (from Twisted>=18.9.0->scrapy)\n",
            "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting incremental>=22.10.0 (from Twisted>=18.9.0->scrapy)\n",
            "  Downloading incremental-22.10.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from Twisted>=18.9.0->scrapy) (4.10.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from tldextract->scrapy) (3.6)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from tldextract->scrapy) (2.31.0)\n",
            "Collecting requests-file>=1.4 (from tldextract->scrapy)\n",
            "  Downloading requests_file-2.0.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract->scrapy) (3.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from automat>=0.8.0->Twisted>=18.9.0->scrapy) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->scrapy) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract->scrapy) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract->scrapy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract->scrapy) (2024.2.2)\n",
            "Installing collected packages: PyDispatcher, incremental, zope.interface, w3lib, queuelib, protego, jmespath, itemadapter, hyperlink, cssselect, constantly, automat, Twisted, requests-file, parsel, tldextract, service-identity, itemloaders, scrapy\n",
            "Successfully installed PyDispatcher-2.0.7 Twisted-24.3.0 automat-22.10.0 constantly-23.10.4 cssselect-1.2.0 hyperlink-21.0.0 incremental-22.10.0 itemadapter-0.8.0 itemloaders-1.1.0 jmespath-1.0.1 parsel-1.8.1 protego-0.3.0 queuelib-1.6.2 requests-file-2.0.0 scrapy-2.11.1 service-identity-24.1.0 tldextract-5.1.1 w3lib-2.1.2 zope.interface-6.2\n",
            "Collecting requests-html\n",
            "  Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from requests-html) (2.31.0)\n",
            "Collecting pyquery (from requests-html)\n",
            "  Downloading pyquery-2.0.0-py3-none-any.whl (22 kB)\n",
            "Collecting fake-useragent (from requests-html)\n",
            "  Downloading fake_useragent-1.5.0-py3-none-any.whl (17 kB)\n",
            "Collecting parse (from requests-html)\n",
            "  Downloading parse-1.20.1-py2.py3-none-any.whl (20 kB)\n",
            "Collecting bs4 (from requests-html)\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Requirement already satisfied: w3lib in /usr/local/lib/python3.10/dist-packages (from requests-html) (2.1.2)\n",
            "Collecting pyppeteer>=0.0.14 (from requests-html)\n",
            "  Downloading pyppeteer-2.0.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (1.4.4)\n",
            "Requirement already satisfied: certifi>=2023 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (2024.2.2)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (7.0.2)\n",
            "Collecting pyee<12.0.0,>=11.0.0 (from pyppeteer>=0.0.14->requests-html)\n",
            "  Downloading pyee-11.1.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (4.66.2)\n",
            "Collecting urllib3<2.0.0,>=1.25.8 (from pyppeteer>=0.0.14->requests-html)\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<11.0,>=10.0 (from pyppeteer>=0.0.14->requests-html)\n",
            "  Downloading websockets-10.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4->requests-html) (4.12.3)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.10/dist-packages (from pyquery->requests-html) (4.9.4)\n",
            "Requirement already satisfied: cssselect>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyquery->requests-html) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->requests-html) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->requests-html) (3.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyee<12.0.0,>=11.0.0->pyppeteer>=0.0.14->requests-html) (4.10.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4->requests-html) (2.5)\n",
            "Installing collected packages: parse, fake-useragent, websockets, urllib3, pyquery, pyee, pyppeteer, bs4, requests-html\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "Successfully installed bs4-0.0.2 fake-useragent-1.5.0 parse-1.20.1 pyee-11.1.0 pyppeteer-2.0.0 pyquery-2.0.0 requests-html-0.10.0 urllib3-1.26.18 websockets-10.4\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.18.1-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.26.18)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.24.0-py3-none-any.whl (460 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m460.2/460.2 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.2.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.10.0)\n",
            "Requirement already satisfied: attrs>=20.1.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.6)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: outcome, h11, wsproto, trio, trio-websocket, selenium\n",
            "Successfully installed h11-0.14.0 outcome-1.3.0.post0 selenium-4.18.1 trio-0.24.0 trio-websocket-0.11.1 wsproto-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install lxml\n",
        "!pip install scrapy\n",
        "!pip3 install requests-html\n",
        "!pip3 install selenium"
      ],
      "id": "79e2c30d"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7h9wGJ10vay",
        "outputId": "9ed1e905-12c0-47e3-fb76-972749cdd60b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com] [1 InRelease 2,585 B/110 kB 2%] [Connecte\u001b[0m\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [736 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,568 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,078 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,960 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,350 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,847 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [33.3 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [80.9 kB]\n",
            "Fetched 8,998 kB in 2s (3,659 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "38 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "wget is already the newest version (1.21.2-2ubuntu1).\n",
            "curl is already the newest version (7.81.0-1ubuntu1.15).\n",
            "unzip is already the newest version (6.0-26ubuntu3.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n",
            "--2024-03-12 23:39:48--  http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\n",
            "Resolving archive.ubuntu.com (archive.ubuntu.com)... 185.125.190.39, 91.189.91.81, 185.125.190.36, ...\n",
            "Connecting to archive.ubuntu.com (archive.ubuntu.com)|185.125.190.39|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3708 (3.6K) [application/x-debian-package]\n",
            "Saving to: ‘libu2f-udev_1.1.4-1_all.deb’\n",
            "\n",
            "libu2f-udev_1.1.4-1 100%[===================>]   3.62K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-12 23:39:49 (314 MB/s) - ‘libu2f-udev_1.1.4-1_all.deb’ saved [3708/3708]\n",
            "\n",
            "Selecting previously unselected package libu2f-udev.\n",
            "(Reading database ... 121752 files and directories currently installed.)\n",
            "Preparing to unpack libu2f-udev_1.1.4-1_all.deb ...\n",
            "Unpacking libu2f-udev (1.1.4-1) ...\n",
            "Setting up libu2f-udev (1.1.4-1) ...\n",
            "--2024-03-12 23:39:50--  https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
            "Resolving dl.google.com (dl.google.com)... 173.194.210.136, 173.194.210.190, 173.194.210.93, ...\n",
            "Connecting to dl.google.com (dl.google.com)|173.194.210.136|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 106053828 (101M) [application/x-debian-package]\n",
            "Saving to: ‘google-chrome-stable_current_amd64.deb’\n",
            "\n",
            "google-chrome-stabl 100%[===================>] 101.14M   284MB/s    in 0.4s    \n",
            "\n",
            "2024-03-12 23:39:50 (284 MB/s) - ‘google-chrome-stable_current_amd64.deb’ saved [106053828/106053828]\n",
            "\n",
            "Selecting previously unselected package google-chrome-stable.\n",
            "(Reading database ... 121756 files and directories currently installed.)\n",
            "Preparing to unpack google-chrome-stable_current_amd64.deb ...\n",
            "Unpacking google-chrome-stable (122.0.6261.128-1) ...\n",
            "\u001b[1mdpkg:\u001b[0m dependency problems prevent configuration of google-chrome-stable:\n",
            " google-chrome-stable depends on libvulkan1; however:\n",
            "  Package libvulkan1 is not installed.\n",
            "\n",
            "\u001b[1mdpkg:\u001b[0m error processing package google-chrome-stable (--install):\n",
            " dependency problems - leaving unconfigured\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Errors were encountered while processing:\n",
            " google-chrome-stable\n",
            "--2024-03-12 23:40:03--  https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/120.0.6099.62/linux64/chromedriver-linux64.zip\n",
            "Resolving edgedl.me.gvt1.com (edgedl.me.gvt1.com)... 34.104.35.123, 2600:1900:4110:86f::\n",
            "Connecting to edgedl.me.gvt1.com (edgedl.me.gvt1.com)|34.104.35.123|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8574825 (8.2M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/chromedriver-linux64.zip’\n",
            "\n",
            "chromedriver-linux6 100%[===================>]   8.18M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-03-12 23:40:04 (74.7 MB/s) - ‘/tmp/chromedriver-linux64.zip’ saved [8574825/8574825]\n",
            "\n",
            "Archive:  /tmp/chromedriver-linux64.zip\n",
            "  inflating: /tmp/chromedriver-linux64/LICENSE.chromedriver  \n",
            "  inflating: /tmp/chromedriver-linux64/chromedriver  \n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (4.18.1)\n",
            "Collecting chromedriver_autoinstaller\n",
            "  Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.26.18)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.24.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.11.1)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.2.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.10.0)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from chromedriver_autoinstaller) (23.2)\n",
            "Requirement already satisfied: attrs>=20.1.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.6)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Installing collected packages: chromedriver_autoinstaller\n",
            "Successfully installed chromedriver_autoinstaller-0.6.4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "%%shell\n",
        "# Install chromedriver\n",
        "# Credits: https://medium.com/@MinatoNamikaze02/running-selenium-on-google-colab-a118d10ca5f8\n",
        "sudo apt -y update\n",
        "sudo apt install -y wget curl unzip\n",
        "wget http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\n",
        "dpkg -i libu2f-udev_1.1.4-1_all.deb\n",
        "wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "dpkg -i google-chrome-stable_current_amd64.deb\n",
        "\n",
        "wget -N https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/120.0.6099.62/linux64/chromedriver-linux64.zip -P /tmp/\n",
        "unzip -o /tmp/chromedriver-linux64.zip -d /tmp/\n",
        "chmod +x /tmp/chromedriver-linux64/chromedriver\n",
        "mv /tmp/chromedriver-linux64/chromedriver /usr/local/bin/chromedriver\n",
        "\n",
        "pip install selenium chromedriver_autoinstaller"
      ],
      "id": "g7h9wGJ10vay"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "634627c4"
      },
      "source": [
        "### Web Scraping Used Car Sales Data\n",
        "This section explains the web scraping process implemented to obtain the data from the used car sales web site [Tu Carro](www.tucarro.com.co)."
      ],
      "id": "634627c4"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acbXwZHSLuSK",
        "outputId": "b76b7f60-910e-46ba-a93f-b53b742c58fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting undetected_chromedriver\n",
            "  Downloading undetected-chromedriver-3.5.5.tar.gz (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.4/65.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: selenium>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from undetected_chromedriver) (4.18.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from undetected_chromedriver) (2.31.0)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from undetected_chromedriver) (10.4)\n",
            "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium>=4.9.0->undetected_chromedriver) (1.26.18)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium>=4.9.0->undetected_chromedriver) (0.24.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium>=4.9.0->undetected_chromedriver) (0.11.1)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium>=4.9.0->undetected_chromedriver) (2024.2.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from selenium>=4.9.0->undetected_chromedriver) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->undetected_chromedriver) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->undetected_chromedriver) (3.6)\n",
            "Requirement already satisfied: attrs>=20.1.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium>=4.9.0->undetected_chromedriver) (23.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium>=4.9.0->undetected_chromedriver) (2.4.0)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium>=4.9.0->undetected_chromedriver) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium>=4.9.0->undetected_chromedriver) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium>=4.9.0->undetected_chromedriver) (1.2.0)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium>=4.9.0->undetected_chromedriver) (1.2.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium>=4.9.0->undetected_chromedriver) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium>=4.9.0->undetected_chromedriver) (0.14.0)\n",
            "Building wheels for collected packages: undetected_chromedriver\n",
            "  Building wheel for undetected_chromedriver (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for undetected_chromedriver: filename=undetected_chromedriver-3.5.5-py3-none-any.whl size=47046 sha256=27c3099286d99bf864ca1711526e39d5cc03aa4eb8a542038ba6b298eba7db2d\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/a1/db/e1275b6f7259aacd6b045f8bfcb1fcbc93827a3916ba55d5b7\n",
            "Successfully built undetected_chromedriver\n",
            "Installing collected packages: undetected_chromedriver\n",
            "Successfully installed undetected_chromedriver-3.5.5\n"
          ]
        }
      ],
      "source": [
        "!pip install undetected_chromedriver"
      ],
      "id": "acbXwZHSLuSK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cee4321"
      },
      "source": [
        "## Import required libraries\n",
        "\n",
        "\n",
        "---"
      ],
      "id": "2cee4321"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p301W6XKx_3x",
        "outputId": "cd1cdbed-ca85-40a2-ea56-70e990ee33f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chromedriver-autoinstaller in /usr/local/lib/python3.10/dist-packages (0.6.4)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from chromedriver-autoinstaller) (23.2)\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "credits:\n",
        "https://github.com/googlecolab/colabtools/issues/3347\n",
        "https://stackoverflow.com/questions/51046454/how-can-we-use-selenium-webdriver-in-colab-research-google-com\n",
        "Sept 19, 2023\n",
        "'''\n",
        "\n",
        "#\n",
        "!pip3 install chromedriver-autoinstaller"
      ],
      "id": "p301W6XKx_3x"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "a6wYT0pimKyC"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup as bs\n",
        "from selenium import webdriver\n",
        "import chromedriver_autoinstaller"
      ],
      "id": "a6wYT0pimKyC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yH4V_gqSoMY3"
      },
      "source": [
        "## Setup chrome and chrome driver\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "id": "yH4V_gqSoMY3"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bkwNiDUhoSIO",
        "outputId": "cb3ffbd6-0689-4ec2-c6e1-5bc292d6190e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/usr/local/lib/python3.10/dist-packages/chromedriver_autoinstaller/122/chromedriver'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# setup chrome options\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless') # ensure GUI is off\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "# # set path to chromedriver as per your configuration\n",
        "chromedriver_autoinstaller.install()"
      ],
      "id": "bkwNiDUhoSIO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtniE5ULxd13"
      },
      "source": [
        "\n",
        "## Section to declare functions\n",
        "\n",
        "---\n",
        "\n"
      ],
      "id": "BtniE5ULxd13"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuMHDnfslfak"
      },
      "source": [
        "### Function scrapebyPages"
      ],
      "id": "RuMHDnfslfak"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0b4086fc"
      },
      "outputs": [],
      "source": [
        "def scrapebyPages(brand,model,min, max):\n",
        "  #Range of pages from the total search to scrape in.\n",
        "  #It is recomended to cover a range of one hundred pages in each iteration of this section.\n",
        "  data = pd.DataFrame()\n",
        "  for i in range(min,max):\n",
        "\n",
        "      print(f'************************************')\n",
        "      print(f'WEB SCRAPING FROM SEARCH PAGE #{i}')\n",
        "      pag = i\n",
        "      url = f'https://vehiculos.tucarro.com.co/{brand}/{model}/_Desde_{49*i}_NoIndex_True'\n",
        "      # url = f'https://vehiculos.tucarro.com.co/maxda-cx-30_Desde_{49*i}_NoIndex_True'\n",
        "      # print(url)\n",
        "\n",
        "      driver = webdriver.Chrome(options=chrome_options)\n",
        "      driver.get(url)\n",
        "      driver.implicitly_wait(10)\n",
        "      html = driver.page_source\n",
        "      soup = bs(html,'lxml')\n",
        "\n",
        "      #Get href\n",
        "      links = gethref(soup)\n",
        "\n",
        "      #Scrapping\n",
        "      # for i in range(0,5):\n",
        "      #   soup = scrapper(links[i])\n",
        "      #   # print(soup)\n",
        "\n",
        "      p = []\n",
        "      # cols = ['car_model','price','year_model','kms']\n",
        "      # data = pd.DataFrame(columns=cols)\n",
        "      #Scrapping a los inmuebles filtrados\n",
        "      # for i in range(len(links)):\n",
        "      for i in range(0,len(links)):\n",
        "          print('Scrapping', i, '/', len(links), '...')\n",
        "          p.append(scrapper(links[i]))\n",
        "          print(f'Este es el valor de p[i]: {p[i]}')\n",
        "\n",
        "      # #append list to DataFrame\n",
        "      data = data.append(p, ignore_index = True)\n",
        "      # print(f'This is the dataset:\\n {data}')\n",
        "\n",
        "  #Close the web browser tab\n",
        "  driver.close()\n",
        "\n",
        "  # quit the driver\n",
        "  driver.quit()\n",
        "\n",
        "  return data"
      ],
      "id": "0b4086fc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcITlNc7kZUU"
      },
      "source": [
        "### Function gethref"
      ],
      "id": "wcITlNc7kZUU"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3ae3aaa8"
      },
      "outputs": [],
      "source": [
        "#Function to get 'href' from each article item\n",
        "def gethref(soup):\n",
        "\n",
        "    links = []\n",
        "    for link in soup.findAll('a'):\n",
        "      url_car = link.get('href')\n",
        "      if 'MCO-' in url_car:\n",
        "        # print(url_car)          %Print each car url as a validity test\n",
        "        links.append(url_car)\n",
        "\n",
        "    print(\"Href obtained: \", len(links))\n",
        "\n",
        "    # for article in soup.find_all('article'):\n",
        "    #     url = article.find('a', href=True)\n",
        "    #     if url:\n",
        "    #         link = url['href']\n",
        "    #         links.append(link)\n",
        "    # print(\"Href obtained: \", len(links))\n",
        "\n",
        "    return links\n",
        "    # return"
      ],
      "id": "3ae3aaa8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGDlMylHklWl"
      },
      "source": [
        "### Function scrapper"
      ],
      "id": "OGDlMylHklWl"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3ed603ae"
      },
      "outputs": [],
      "source": [
        "#Function to call housing_features routine on each href\n",
        "def scrapper(url_car):\n",
        "\n",
        "    # set up the webdriver\n",
        "    driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "    # Scrape\n",
        "    driver.get(url_car)\n",
        "    driver.implicitly_wait(10)\n",
        "    html=driver.page_source\n",
        "\n",
        "    #Obtaining the html from the web page after applying Selenium\n",
        "    soup = bs(html,'lxml')\n",
        "\n",
        "    #Create a list to store info obtained from one particular property\n",
        "    features = []\n",
        "\n",
        "    #Applying function to obtain variables defined from one particular property\n",
        "    features = extract_cars_features(soup)\n",
        "\n",
        "    #Close the web browser tab\n",
        "    driver.close()\n",
        "\n",
        "    # quit the driver\n",
        "    driver.quit()\n",
        "\n",
        "    return(features)"
      ],
      "id": "3ed603ae"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuAn5qaikpLH"
      },
      "source": [
        "### Function extract_cars_features"
      ],
      "id": "LuAn5qaikpLH"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "23acf2f0"
      },
      "outputs": [],
      "source": [
        "# Version 1.0\n",
        "def extract_cars_features(soup):\n",
        "\n",
        "  features_list = []\n",
        "\n",
        "  # car_name\n",
        "  try:\n",
        "    car_name = soup.find('h1',{'class': 'ui-pdp-title'}).text\n",
        "    features_list.append(car_name)\n",
        "    # print(f\"Car's name is: {car_name}\")\n",
        "  except:\n",
        "    car_name = ' '\n",
        "    features_list.append(car_name)\n",
        "\n",
        "  # price\n",
        "  try:\n",
        "    price=soup.find('div',{'class': 'ui-pdp-price__second-line'}).text\n",
        "    features_list.append(price)\n",
        "    # print(f\"Car's price is: {price}\")\n",
        "  except:\n",
        "    price = 0\n",
        "    features_list.append(price)\n",
        "\n",
        "  # year_car\n",
        "  try:\n",
        "    year_kms_datePub = soup.find('div',{'class': 'ui-pdp-header__subtitle'}).text.split(' ')\n",
        "    year = year_kms_datePub[0]\n",
        "    features_list.append(year)\n",
        "  except:\n",
        "    year = 0\n",
        "    features_list.append(year)\n",
        "\n",
        "  # kms\n",
        "  try:\n",
        "    year_kms_datePub = soup.find('div',{'class': 'ui-pdp-header__subtitle'}).text.split(' ')\n",
        "    kms = year_kms_datePub[2]\n",
        "    features_list.append(kms)\n",
        "  except:\n",
        "    kms = 0\n",
        "    features_list.append(kms)\n",
        "  # print(f\"Kms: {kms}\")\n",
        "\n",
        "  # # date_publication_1\n",
        "  # datePub = ' '.join(year_kms_datePub[7:])\n",
        "  # features_list.append(datePub)\n",
        "  # # print(f\"Publication date: {datePub}\")\n",
        "\n",
        "\n",
        "  # print(features_list)\n",
        "\n",
        "\n",
        "  return features_list"
      ],
      "id": "23acf2f0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVJILRDRovcE"
      },
      "source": [
        "## Start scraping\n",
        "\n",
        "---"
      ],
      "id": "aVJILRDRovcE"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gXxtjYNpq7_L"
      },
      "outputs": [],
      "source": [
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.by import By"
      ],
      "id": "gXxtjYNpq7_L"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKU4dts4Hb2v",
        "outputId": "c6825b8d-f5d6-4cc3-b762-39be41aee205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "************************************\n",
            "WEB SCRAPING FROM SEARCH PAGE #1\n",
            "Href obtained:  48\n",
            "Scrapping 0 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.4 Vibrant', '$65.900.000', '2023', '37.600']\n",
            "Scrapping 1 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.4 4 p', '$46.500.000', '2014', '73.435']\n",
            "Scrapping 2 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.4 ZENITH', '$61.500.000', '2019', '44.000']\n",
            "Scrapping 3 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio Ex 1 4 Tp 1.4 4p 2ab 2015', '$40.990.000', '2015', '110.540']\n",
            "Scrapping 4 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.4 Vibrant At', '$58.600.000', '2019', '54.105']\n",
            "Scrapping 5 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio FE 1.4 AUT', '$54.500.000', '2018', '61.187']\n",
            "Scrapping 6 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.4 Vibrant Hb 4 p', '$67.900.000', '2023', '28.512']\n",
            "Scrapping 7 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio Ub Ex-1.4 Mec Hb Modelo 2017 45677', '$47.300.000', '2017', '104.632']\n",
            "Scrapping 8 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.4 Vibrant Mt', '$74.900.000', '2023', '13.690']\n",
            "Scrapping 9 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio R 1.4 Modelo 2017 Id 45918', '$50.900.000', '2017', '74.030']\n",
            "Scrapping 10 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio Vibrant At 1.4', '$64.900.000', '2023', '23.000']\n",
            "Scrapping 11 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.4 Zenith Automatico', '$73.900.000', '2022', '31.212']\n",
            "Scrapping 12 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.4 Vibrant', '$54.000.000', '2019', '50.000']\n",
            "Scrapping 13 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.4 Zenith', '$58.000.000', '2018', '77.800']\n",
            "Scrapping 14 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio Vibrant', '$75.490.000', '2024', '0']\n",
            "Scrapping 15 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio Emotion AT 1.4 2020', '$58.900.000', '2020', '52.000']\n",
            "Scrapping 16 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio Zenith At 1.4', '$69.900.000', '2023', '22.000']\n",
            "Scrapping 17 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.4', '$65.900.000', '2022', '20.600']\n",
            "Scrapping 18 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.4 Vibrant At', '$64.990.000', '2022', '21.100']\n",
            "Scrapping 19 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.4 Vibrant At', '$66.900.000', '2022', '39.000']\n",
            "Scrapping 20 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.4 Vibrant Hb 4 p', '$68.990.000', '2023', '31.970']\n",
            "Scrapping 21 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.4', '$74.900.000', '2023', '9.850']\n",
            "Scrapping 22 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.4 Sc Nb', '$66.000.000', '2021', '30.000']\n",
            "Scrapping 23 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio Vibrant', '$74.990.000', '2024', '0']\n",
            "Scrapping 24 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.4 Emotion Hb', '$52.500.000', '2019', '125.600']\n",
            "Scrapping 25 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio Spice 1.4', '$41.500.000', '2015', '59.900']\n",
            "Scrapping 26 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio Spice 1.4', '$40.000.000', '2015', '122.700']\n",
            "Scrapping 27 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.4 Vibrant Hb 5 p', '$73.000.000', '2023', '21.900']\n",
            "Scrapping 28 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.4 Zenith Hb 5 p', '$65.000.000', '2021', '47.000']\n",
            "Scrapping 29 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio VIBRANT', '$59.000.000', '2018', '68.000']\n",
            "Scrapping 30 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.4 Vibrant Hb', '$49.000.000', '2021', '22.000']\n",
            "Scrapping 31 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.2 4 p', '$44.500.000', '2017', '60.000']\n",
            "Scrapping 32 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.4 Vibrant Hb 4 p', '$70.900.000', '2022', '17.000']\n",
            "Scrapping 33 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio', '$40.900.000', '2014', '41.830']\n",
            "Scrapping 34 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.4 4 p Automática', '$49.900.000', '2017', '53.195']\n",
            "Scrapping 35 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.4', '$59.990.000', '2022', '35.000']\n",
            "Scrapping 36 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio Ub Ex 1.4 At 2014', '$41.900.000', '2014', '111.202']\n",
            "Scrapping 37 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.4 ZENITH MT TECHO', '$73.600.000', '2023', '11.000']\n",
            "Scrapping 38 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio Spice R Summa 1.250', '$50.000.000', '2017', '84.000']\n",
            "Scrapping 39 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.4 4 p', '$38.000.000', '2013', '117.300']\n",
            "Scrapping 40 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.4', '$58.000.000', '2020', '57.114']\n",
            "Scrapping 41 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.4 Vibrant Hb 5 p', '$60.500.000', '2020', '53.000']\n",
            "Scrapping 42 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.4 Vibrant Hb', '$63.000.000', '2021', '36.572']\n",
            "Scrapping 43 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.4 5 p', '$47.000.000', '2016', '100.000']\n",
            "Scrapping 44 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.25', '$48.000.000', '2017', '69.400']\n",
            "Scrapping 45 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.4 5 p 95 hp', '$33.000.000', '2012', '130.000']\n",
            "Scrapping 46 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.4 Vibrant Mt', '$51.000.000', '2018', '56.775']\n",
            "Scrapping 47 / 48 ...\n",
            "Este es el valor de p[i]: ['Kia Rio 1.5 Stylus', '$31.000.000', '2016', '91.500']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-d9697e0ef0fd>:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  data = data.append(p, ignore_index = True)\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        " The input parameters for the 'scrapebyPages' function are: Brand name, Car model\n",
        " name. Be careful to write the brand and model names exactly as they are in tucarro.com.\n",
        " The third input parameter is the initial results page (always initialize to 1)\n",
        " and the fourth input parameter is the final results page you want to download data from;\n",
        " this parameter depends on the amount of results pages your car returns\n",
        " for the brand and model you want to get data from. So, it is recommended to search\n",
        " the web portal first to find out how many pages of results you can get\n",
        " for the car you want to get data from.\n",
        "\"\"\"\n",
        "\n",
        "car_brand = 'kia'   # Brand car name. Ej: chevrolet, renault, kia.\n",
        "car_model = 'rio'        # Model car name. Ej: duster, onix, rio.\n",
        "data = scrapebyPages(car_brand,car_model,1,2)\n",
        "# scrapebyPages(1,2)"
      ],
      "id": "MKU4dts4Hb2v"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "SalqwDzWlrqG",
        "outputId": "35fffcfe-01ee-4cc4-bdb8-03b2be5c1b00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48, 4)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           car_model        price year_model      kms\n",
              "0                Kia Rio 1.4 Vibrant  $65.900.000       2023   37.600\n",
              "1                    Kia Rio 1.4 4 p  $46.500.000       2014   73.435\n",
              "2                 Kia Rio 1.4 ZENITH  $61.500.000       2019   44.000\n",
              "3  Kia Rio Ex 1 4 Tp 1.4 4p 2ab 2015  $40.990.000       2015  110.540\n",
              "4             Kia Rio 1.4 Vibrant At  $58.600.000       2019   54.105"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f1a5cf87-b855-4006-b4ac-9c10e06c9c83\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>car_model</th>\n",
              "      <th>price</th>\n",
              "      <th>year_model</th>\n",
              "      <th>kms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Kia Rio 1.4 Vibrant</td>\n",
              "      <td>$65.900.000</td>\n",
              "      <td>2023</td>\n",
              "      <td>37.600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Kia Rio 1.4 4 p</td>\n",
              "      <td>$46.500.000</td>\n",
              "      <td>2014</td>\n",
              "      <td>73.435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kia Rio 1.4 ZENITH</td>\n",
              "      <td>$61.500.000</td>\n",
              "      <td>2019</td>\n",
              "      <td>44.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Kia Rio Ex 1 4 Tp 1.4 4p 2ab 2015</td>\n",
              "      <td>$40.990.000</td>\n",
              "      <td>2015</td>\n",
              "      <td>110.540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Kia Rio 1.4 Vibrant At</td>\n",
              "      <td>$58.600.000</td>\n",
              "      <td>2019</td>\n",
              "      <td>54.105</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1a5cf87-b855-4006-b4ac-9c10e06c9c83')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f1a5cf87-b855-4006-b4ac-9c10e06c9c83 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f1a5cf87-b855-4006-b4ac-9c10e06c9c83');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-18ffa1bd-220a-46b2-9b38-f893cd0e4ed7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-18ffa1bd-220a-46b2-9b38-f893cd0e4ed7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-18ffa1bd-220a-46b2-9b38-f893cd0e4ed7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 48,\n  \"fields\": [\n    {\n      \"column\": \"car_model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 34,\n        \"samples\": [\n          \"Kia Rio Zenith At 1.4\",\n          \"Kia Rio Spice 1.4\",\n          \"Kia Rio Ub Ex 1.4 At 2014\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 45,\n        \"samples\": [\n          \"$63.000.000\",\n          \"$73.000.000\",\n          \"$65.000.000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year_model\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"2016\",\n          \"2021\",\n          \"2023\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"kms\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 46,\n        \"samples\": [\n          \"53.000\",\n          \"122.700\",\n          \"21.900\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "cols = ['car_model','price','year_model','kms']\n",
        "data.columns = cols\n",
        "print(data.shape)\n",
        "data.head()"
      ],
      "id": "SalqwDzWlrqG"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "hpUV4SB9lrsq"
      },
      "outputs": [],
      "source": [
        "saved_name=f'usedCarsCol_{car_model}_120324_small.csv'\n",
        "data.to_csv(saved_name, encoding='utf-8', index=False)"
      ],
      "id": "hpUV4SB9lrsq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOecwhsPrKQ6"
      },
      "source": [
        "### Testing code for scraping only one page"
      ],
      "id": "uOecwhsPrKQ6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_szzIxMF9dY"
      },
      "outputs": [],
      "source": [
        "#*****************************\n",
        "#Code for testing in one page\n",
        "#*****************************\n",
        "\n",
        "# # set the target URL\n",
        "# pag = 1\n",
        "# url = f'https://www.fincaraiz.com.co/apartamentos-casas/venta/bogota/bogota-dc?pagina={pag}'\n",
        "\n",
        "# # set up the webdriver\n",
        "# driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "# print(url)\n",
        "# driver.get(url)\n",
        "# driver.implicitly_wait(10)\n",
        "# html = driver.page_source\n",
        "# soup = bs(html,'lxml')\n",
        "\n",
        "# # quit the driver\n",
        "# driver.quit()\n",
        "\n",
        "# links = []\n",
        "# links = gethref(soup)\n",
        "# links\n",
        "\n",
        "# aux = []\n",
        "# cols = ['habitaciones','baños','parqueaderos','area_construida','area_privada','estrato','estado','antiguedad',\n",
        "#         'administracion','precio_m2', 'Ascensor', 'Circuito cerrado de TV',\n",
        "#        'Parqueadero Visitantes', 'Portería / Recepción', 'Zonas Verdes', 'Salón Comunal', 'Balcón',\n",
        "#        'Barra estilo americano', 'Calentador', 'Chimenea', 'Citófono', 'Cocina Integral', 'Terraza',\n",
        "#        'Vigilancia', 'Parques cercanos', 'Estudio', 'Patio', 'Depósito / Bodega', 'nombre','ubicacion','precio']\n",
        "# data = pd.DataFrame(columns=cols)\n",
        "\n",
        "# #Remove \"Proyectos de vivienda\"\n",
        "# url_inmuebles = []\n",
        "# url_inmuebles = remove_proyectos(links)\n",
        "\n",
        "# #Scrapping\n",
        "# p = []\n",
        "# #Scrapping a los inmuebles filtrados\n",
        "# for i in range(len(url_inmuebles)):\n",
        "#   print('Scrapping', i, '/', len(url_inmuebles), '...')\n",
        "#   p.append(scrapper(url_inmuebles[i]))\n",
        "#   print(p[i])\n",
        "\n",
        "#   #append list to DataFrame\n",
        "#   data.loc[len(data)] = p[i]"
      ],
      "id": "L_szzIxMF9dY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4c68c33"
      },
      "source": [
        "## Referencias\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "https://github.com/kiteco/kite-python-blog-post-code/blob/master/Web%20Scraping%20Tutorial/script.py\n",
        "\n",
        "https://medium.com/geekculture/scrappy-guide-to-web-scraping-with-python-475385364381\n",
        "\n",
        "https://stackoverflow.com/questions/47730671/python-3-using-requests-does-not-get-the-full-content-of-a-web-page"
      ],
      "id": "b4c68c33"
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "bc4c3640",
        "2cee4321",
        "yH4V_gqSoMY3",
        "RuMHDnfslfak",
        "wcITlNc7kZUU",
        "OGDlMylHklWl",
        "LuAn5qaikpLH",
        "uOecwhsPrKQ6"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}